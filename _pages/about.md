---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- Default Statcounter code for Personal
https://ethanm88.github.io/ -->
<script type="text/javascript">
var sc_project=12951358; 
var sc_invisible=1; 
var sc_security="1e65b810"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12951358/0/1e65b810/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

Hello! I am a ML Ph.D. student at Georgia Tech where I work on Natural Language Processing (NLP) and am advised by [Prof. Alan Ritter](http://aritter.github.io/). Previously, I interned at the [Center for Human-Compatible Artificial Intelligence (CHAI)](https://humancompatible.ai/) at UC Berkeley working in [Prof. Stuart Russell's](https://people.eecs.berkeley.edu/~russell/) group.

<!-- **Current Research Interests:** I am interested in building and evaluating efficient human-in-the-loop (HITL) systems and investigating applications of HITL learning that can be deployed to critical domains (e.g. misinformation). Additionally, I am interested in large language model (LLM) robustness, specifically as it relates to privacy-preservation and model hijacking.


**I am applying to ML/NLP Ph.D. programs in Fall 2023.** -->

Feel free to reach out at emendes3[at]gatech[dot]edu.

Publications
======
- ***Granular Privacy Control for Geolocation with Vision Language Models*** <br>
**Ethan Mendes**, [Yang Chen](https://edchengg.github.io/), [James Hays](https://faculty.cc.gatech.edu/~hays/), [Sauvik Das](https://sauvikdas.com/), [Wei Xu](https://cocoxu.github.io/), [Alan Ritter](http://aritter.github.io/) <br>
EMNLP 2024 **(Oral)** <br>
\[[paper](https://arxiv.org/pdf/2407.04952)\] \[[data / code](https://github.com/ethanm88/GPTGeoChat)\]

- ***ChatHF: Collecting Rich Human Feedback from Real-time Conversations*** <br>
Andrew Li, [Zhenduo Wang](https://zhenduow.github.io/), **Ethan Mendes**, [Duong Minh Le](https://duonglm38.github.io/), [Wei Xu](https://cocoxu.github.io/), [Alan Ritter](http://aritter.github.io/) <br>
EMNLP 2024 (Demo) <br>
\[[paper](https://aclanthology.org/2024.emnlp-demo.28.pdf)\]

- ***Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game*** <br>
[Sam Toyer](https://www.qxcv.net/), [Olivia Watkins](https://aliengirlliv.github.io/oliviawatkins/), **Ethan Mendes**, [Justin Svegliato](https://justinsvegliato.com/), [Luke Bailey](https://scholar.google.com/citations?user=rUr9LjMAAAAJ&hl=en), [Tiffany Wang](https://www.tiffanywang.me/), [Isaac Ong](https://isaacong.me/), [Karim Elmaaroufi](https://kael.tech.blog/), [Pieter Abbeel](https://people.eecs.berkeley.edu/~pabbeel/), [Trevor Darrell](https://people.eecs.berkeley.edu/~trevor/), [Alan Ritter](http://aritter.github.io/), [Stuart Russell](https://people.eecs.berkeley.edu/~russell/) <br>
ICLR 2024 **(Spotlight)** <br>
Previously presented: <br>
Instruction Tuning and Instruction Following Workshop at NeurIPS 2023 **(Oral and Honorable Mention)** <br>
R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Foundation Models Workshop at NeurIPS 2023 **(Spotlight)** <br>
\[[paper](https://arxiv.org/pdf/2311.01011.pdf)\] \[[data](https://github.com/HumanCompatibleAI/tensor-trust-data)\] \[[code](https://github.com/HumanCompatibleAI/tensor-trust)\] \[[project page](https://tensortrust.ai/paper/)\]

- ***Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments*** <br>
**Ethan Mendes**, [Yang Chen](https://edchengg.github.io/), [Wei Xu](https://cocoxu.github.io/), [Alan Ritter](http://aritter.github.io/) <br>
ACL 2023 <br>
\[[paper](https://aclanthology.org/2023.acl-long.881.pdf)\] \[[data](https://github.com/ethanm88/hitl-evaluation-early-misinformation-detection)\]


Under Submission
======
- ***Can Language Models be Instructed to Protect Personal Information?*** <br>
[Yang Chen\*](https://edchengg.github.io/), **Ethan Mendes\***, [Sauvik Das](https://sauvikdas.com/), [Wei Xu](https://cocoxu.github.io/), [Alan Ritter](http://aritter.github.io/) <br>
\[[paper](https://arxiv.org/pdf/2310.02224.pdf)\] \[[data](https://github.com/ethanm88/llm-access-control)\] \[[project page](https://llm-access-control.github.io/)\]


Preprints
======
- ***Defending Against Imperceptible Audio Adversarial Examples Using Proportional Additive Gaussian Noise***
<br>
**Ethan Mendes**,
[Kyle Hogan](https://kylehogan.github.io/) <br>
\[[paper](https://kleinex.mit.edu/research/highschool/primes/materials/2020/Mendes-Hogan.pdf)\]
